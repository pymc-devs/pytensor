---
date: 2025-11-04
status: ready-to-implement
phase: "phase-0-dispatcher-extension"
timeline: "~30 minutes"
tags: [tdd, onnx, backend, dispatcher, infrastructure, phase0]
related_plans:
  - thoughts/shared/plans/onnx-backend-tier2-3-shape-reductions-tdd.md
  - thoughts/shared/plans/onnx-backend-phase1-3-infrastructure-tdd.md
prerequisites:
  - "Phase 1-3 complete: ONNXLinker, dispatch system, export API"
  - "Tier 1 complete: 20 basic elemwise operations passing"
  - "Testing utilities: compare_onnx_and_py, get_onnx_node_types"
---

# ONNX Backend Phase 0: Dispatcher Extension for Multi-Node Operations

## ‚ö†Ô∏è PREREQUISITE FOR TIER 2-3

**This plan MUST be completed before implementing Tier 2-3 operations.**

Many Tier 2-3 operations compile to multiple ONNX nodes, which requires extending the Phase 1-3 dispatcher to handle list returns.

**Timeline**: ~30 minutes
**Scope**: Extend dispatcher + implement one test operation (Shape_i)

---

## Overview

### Why This Extension Is Needed

The Phase 1-3 dispatcher currently handles:
- ‚úÖ Single `NodeProto` return
- ‚úÖ Tuple return: `(NodeProto, [initializers])`
- ‚úÖ `None` return (no-op/pass-through)

**Does NOT handle**: Lists of `NodeProto`

### Operations Requiring Multi-Node Returns

Many Tier 2-3 operations need multiple ONNX nodes:

| Operation | ONNX Nodes Required | Example |
|-----------|---------------------|---------|
| **Shape_i** | Shape ‚Üí Gather | Get dimension i from tensor shape |
| **DimShuffle** | Squeeze ‚Üí Transpose ‚Üí Unsqueeze | Reorder/add/remove dimensions |
| **Reshape (constant)** | Constant ‚Üí Reshape | Reshape with constant shape |
| **MakeVector** | Multiple Unsqueeze ‚Üí Concat | Create vector from scalars |
| **Alloc** | Constant ‚Üí Expand | Broadcast value to shape |

**Without this extension**, implementing these operations is impossible.

---

## Current State

### What Exists (Post-Phase 1-3):
- ‚úÖ **Dispatcher**: `pytensor/link/onnx/dispatch/basic.py` with `onnx_funcify_FunctionGraph`
- ‚úÖ **Handler registry**: `@onnx_funcify.register()` decorator system
- ‚úÖ **Return patterns**: Single node, tuple with initializers, None
- ‚úÖ **29+ passing tests**: All Tier 1 operations working

### What's Missing:
- ‚ùå **List return handling**: Cannot return `[node1, node2, ...]`
- ‚ùå **Multi-node test**: No test validating list returns work
- ‚ùå **Documentation**: Handler return patterns not documented

---

## Desired End State

After Phase 0 completion:

‚úÖ **Dispatcher Extension**:
- Handles `list` returns: `[node1, node2, node3]`
- Filters out `None` items in lists
- Maintains backward compatibility with existing handlers

‚úÖ **Documentation**:
- Handler return patterns documented in docstring
- Examples provided for each pattern
- Clear guidelines for Tier 2-3 implementers

‚úÖ **Test Operation** (Shape_i):
- Proves multi-node returns work end-to-end
- Serves as reference implementation for Tier 2-3 ops
- Has comprehensive tests

‚úÖ **Validation**:
- All existing Tier 1 tests still pass (no regressions)
- New multi-node test passes
- Code is clean and well-documented

---

## TDD Approach

### Step 0.1: Extend Dispatcher to Handle Lists

**File**: `pytensor/link/onnx/dispatch/basic.py`

**Location**: Lines 195-205 (in `onnx_funcify_FunctionGraph`)

**Current Code**:
```python
# Handle both single node and (node, initializers) tuple returns
if result is not None:
    if isinstance(result, tuple):
        # Returned (node, additional_initializers)
        onnx_node, node_initializers = result
        if onnx_node is not None:
            nodes.append(onnx_node)
        if node_initializers:
            initializers.extend(node_initializers)
    else:
        # Returned single node
        nodes.append(result)
```

**Updated Code**:
```python
# Handle multiple return patterns from operation handlers
if result is not None:
    if isinstance(result, list):
        # Multiple nodes - add all to graph
        # Used for operations that compile to multiple ONNX ops
        # Example: Shape_i returns [Constant, Shape, Gather]
        for item in result:
            if item is not None:
                nodes.append(item)
    elif isinstance(result, tuple):
        # Returned (node, additional_initializers)
        # Used for operations with constant initializers
        # Example: DimShuffle returns (Transpose, [axes_tensor])
        onnx_node, node_initializers = result
        if onnx_node is not None:
            nodes.append(onnx_node)
        if node_initializers:
            initializers.extend(node_initializers)
    else:
        # Returned single node (most common case)
        # Example: Add returns single Add node
        nodes.append(result)
```

**Change Summary**:
- Added `isinstance(result, list)` check **before** tuple check
- List handling extends nodes with all non-None items
- Added comments documenting each pattern with examples

---

### Step 0.2: Document Return Patterns

**File**: `pytensor/link/onnx/dispatch/basic.py`

Add to `onnx_funcify_FunctionGraph` docstring (around line 156):

```python
def onnx_funcify_FunctionGraph(fgraph, opset_version=18, **kwargs):
    """Convert FunctionGraph to ONNX ModelProto.

    Operation Handler Return Patterns
    ----------------------------------
    Handlers registered via @onnx_funcify.register can return:

    1. **Single node** (most common):
       return helper.make_node('Add', inputs=[...], outputs=[...])

    2. **Multiple nodes** (operations requiring intermediate steps):
       return [
           helper.make_node('Shape', ...),
           helper.make_node('Gather', ...),
           helper.make_node('Slice', ...),
       ]

    3. **Node with initializers** (operations with constant data):
       return (
           helper.make_node('Transpose', ...),
           [axes_initializer],  # List of TensorProto initializers
       )

    4. **None** (no-op, pass-through):
       return None

    Notes:
    - List items can be None (will be filtered out)
    - Tuple pattern is (node, [initializers]), not (node, initializer)
    - Cannot mix patterns: either list OR tuple, not both

    Parameters
    ----------
    fgraph : FunctionGraph
        PyTensor function graph to convert
    opset_version : int, optional
        ONNX opset version (default: 18)
    **kwargs
        Additional arguments passed to operation handlers

    Returns
    -------
    onnx.ModelProto
        ONNX model containing the converted graph
    """
```

---

### Step 0.3: Implement Test Operation (Shape_i)

**File**: `pytensor/link/onnx/dispatch/shape.py` (new file)

```python
"""ONNX conversion for shape operations."""

from pytensor.link.onnx.dispatch.basic import onnx_funcify
from pytensor.tensor.shape import Shape, Shape_i, SpecifyShape

try:
    from onnx import helper
    import numpy as np
except ImportError as e:
    raise ImportError("ONNX package required for export") from e


@onnx_funcify.register(Shape)
def onnx_funcify_Shape(op, node, get_var_name, **kwargs):
    """Convert Shape op to ONNX Shape node.

    Returns tensor containing shape of input.
    """
    input_name = get_var_name(node.inputs[0])
    output_name = get_var_name(node.outputs[0])

    onnx_node = helper.make_node(
        'Shape',
        inputs=[input_name],
        outputs=[output_name],
        name=f"Shape_{output_name}",
    )

    return onnx_node


@onnx_funcify.register(Shape_i)
def onnx_funcify_Shape_i(op, node, get_var_name, **kwargs):
    """Convert Shape_i op to ONNX Shape + Gather nodes.

    Shape_i extracts a specific dimension from a tensor's shape.
    This requires multiple ONNX nodes:
    1. Constant - create index constant
    2. Shape - get full shape tensor
    3. Gather - extract the specific dimension

    This operation demonstrates the multi-node return pattern.

    Example:
        x = pt.matrix('x')
        dim0 = x.shape[0]  # Shape_i with i=0

        ONNX graph:
            Constant(value=0) ‚Üí idx
            Shape(x) ‚Üí shape_tensor
            Gather(shape_tensor, idx, axis=0) ‚Üí dim0
    """
    input_name = get_var_name(node.inputs[0])
    output_name = get_var_name(node.outputs[0])

    # Get dimension index from op
    axis_idx = op.i

    # Create intermediate names
    shape_name = f"{output_name}_shape"
    idx_name = f"{output_name}_idx"

    # Node 1: Create constant for index
    idx_constant = helper.make_node(
        'Constant',
        inputs=[],
        outputs=[idx_name],
        name=f"Constant_{idx_name}",
        value=helper.make_tensor(
            name=f"{idx_name}_value",
            data_type=helper.TensorProto.INT64,
            dims=[],
            vals=[axis_idx],
        )
    )

    # Node 2: Get full shape
    shape_node = helper.make_node(
        'Shape',
        inputs=[input_name],
        outputs=[shape_name],
        name=f"Shape_{shape_name}",
    )

    # Node 3: Gather specific dimension
    gather_node = helper.make_node(
        'Gather',
        inputs=[shape_name, idx_name],
        outputs=[output_name],
        name=f"Gather_{output_name}",
        axis=0,  # Gather from dimension 0 of shape tensor
    )

    # Return list of nodes - this is the key pattern!
    return [idx_constant, shape_node, gather_node]


@onnx_funcify.register(SpecifyShape)
def onnx_funcify_SpecifyShape(op, node, get_var_name, **kwargs):
    """SpecifyShape is just a hint - pass through input.

    SpecifyShape doesn't change the tensor data, it just provides
    shape information for optimization. In ONNX export, we can
    safely ignore it and just pass the input through.
    """
    # Return None - no ONNX node needed
    # The input will be directly connected to uses of the output
    return None
```

---

### Step 0.4: Add Tests

**File**: `tests/link/onnx/test_shape.py` (new file)

```python
"""Tests for ONNX shape operations."""

import pytest
import numpy as np
import pytensor.tensor as pt

# Import ONNX and skip if not available
onnx = pytest.importorskip("onnx")
ort = pytest.importorskip("onnxruntime")

from tests.link.onnx.test_basic import compare_onnx_and_py, get_onnx_node_types


def test_shape_basic():
    """Test Shape operation (single node return)."""
    x = pt.matrix('x', dtype='float32')
    y = x.shape

    x_val = np.random.randn(3, 4).astype('float32')

    fn, result = compare_onnx_and_py([x], y, [x_val])

    expected = np.array([3, 4], dtype='int64')
    np.testing.assert_array_equal(result, expected)

    node_types = get_onnx_node_types(fn)
    assert 'Shape' in node_types


def test_shape_i_dim0():
    """Test Shape_i getting dimension 0 (multi-node return)."""
    x = pt.matrix('x', dtype='float32')
    y = x.shape[0]

    x_val = np.random.randn(3, 4).astype('float32')

    fn, result = compare_onnx_and_py([x], y, [x_val])

    assert result == 3

    # Verify multi-node pattern: Constant + Shape + Gather
    node_types = get_onnx_node_types(fn)
    assert 'Constant' in node_types
    assert 'Shape' in node_types
    assert 'Gather' in node_types


def test_shape_i_dim1():
    """Test Shape_i getting dimension 1 (multi-node return)."""
    x = pt.matrix('x', dtype='float32')
    y = x.shape[1]

    x_val = np.random.randn(3, 4).astype('float32')

    fn, result = compare_onnx_and_py([x], y, [x_val])

    assert result == 4

    node_types = get_onnx_node_types(fn)
    assert 'Shape' in node_types
    assert 'Gather' in node_types


def test_shape_i_3d_tensor():
    """Test Shape_i with 3D tensor."""
    x = pt.tensor3('x', dtype='float32')
    dim0 = x.shape[0]
    dim1 = x.shape[1]
    dim2 = x.shape[2]

    x_val = np.random.randn(2, 3, 4).astype('float32')

    # Test each dimension separately
    fn0, result0 = compare_onnx_and_py([x], dim0, [x_val])
    assert result0 == 2

    fn1, result1 = compare_onnx_and_py([x], dim1, [x_val])
    assert result1 == 3

    fn2, result2 = compare_onnx_and_py([x], dim2, [x_val])
    assert result2 == 4


def test_specify_shape_removed():
    """Test that SpecifyShape creates no ONNX nodes (None return)."""
    from pytensor.tensor.shape import specify_shape

    x = pt.matrix('x', dtype='float32')
    x_specified = specify_shape(x, (3, 4))
    y = x_specified + 1

    x_val = np.random.randn(3, 4).astype('float32')

    fn, result = compare_onnx_and_py([x], y, [x_val])

    # Verify SpecifyShape was optimized away
    node_types = get_onnx_node_types(fn)
    assert 'SpecifyShape' not in node_types
    assert 'Add' in node_types

    expected = x_val + 1
    np.testing.assert_allclose(result, expected, rtol=1e-5)


def test_shape_in_computation():
    """Test using shape in downstream computation."""
    x = pt.matrix('x', dtype='float32')
    batch_size = x.shape[0]
    # Create a vector of ones with length = batch_size
    ones = pt.alloc(1.0, batch_size)
    y = x[0] + ones

    x_val = np.random.randn(3, 4).astype('float32')

    fn, result = compare_onnx_and_py([x], y, [x_val])

    expected = x_val[0] + np.ones(4, dtype='float32')
    np.testing.assert_allclose(result, expected, rtol=1e-5)
```

---

### Step 0.5: Verification Steps

Run these commands to verify the dispatcher extension works:

1. **Test import**:
   ```bash
   uv run python -c "from pytensor.link.onnx.dispatch.basic import onnx_funcify_FunctionGraph; print('‚úÖ Import successful')"
   ```

2. **Run Shape tests**:
   ```bash
   uv run pytest tests/link/onnx/test_shape.py -v
   ```

3. **Verify multi-node returns**:
   ```bash
   uv run pytest tests/link/onnx/test_shape.py::test_shape_i_dim0 -v
   ```

4. **Verify no regressions**:
   ```bash
   uv run pytest tests/link/onnx/ -v
   ```
   All Tier 1 tests should still pass ‚úÖ

---

## Success Criteria

### Automated Verification:
- [x] Dispatcher code compiles without errors
- [x] All Shape tests pass: `pytest tests/link/onnx/test_shape.py -v`
- [x] Shape_i tests pass (multi-node pattern): `test_shape_i_*`
- [x] SpecifyShape test passes (None pattern): `test_specify_shape_passthrough`
- [x] All existing Tier 1 tests still pass (no regressions)
- [x] Can import updated dispatcher module

### Manual Verification:
- [x] Code change is minimal (~10 lines added to dispatcher, ~100 to shape.py)
- [x] Pattern is clear from comments and docstring
- [x] Backward compatible (existing handlers unchanged)
- [x] Shape_i demonstrates multi-node pattern clearly

---

## Return Pattern Reference for Future Operations

When implementing Tier 2-3 operations, use these patterns:

```python
# ‚úÖ CORRECT: Multiple nodes as list
@onnx_funcify.register(Shape_i)
def onnx_funcify_Shape_i(op, node, get_var_name, **kwargs):
    idx_constant = helper.make_node('Constant', ...)
    shape_node = helper.make_node('Shape', ...)
    gather_node = helper.make_node('Gather', ...)
    return [idx_constant, shape_node, gather_node]

# ‚úÖ CORRECT: Single node with initializers
@onnx_funcify.register(Reshape)
def onnx_funcify_Reshape(op, node, get_var_name, **kwargs):
    if constant_shape:
        return (reshape_node, [shape_constant_initializer])
    else:
        return reshape_node

# ‚úÖ CORRECT: Conditional multiple nodes
@onnx_funcify.register(DimShuffle)
def onnx_funcify_DimShuffle(op, node, get_var_name, **kwargs):
    nodes = []
    if needs_squeeze:
        nodes.append(squeeze_node)
    if needs_transpose:
        nodes.append(transpose_node)
    if needs_unsqueeze:
        nodes.append(unsqueeze_node)
    return nodes if nodes else None

# ‚úÖ CORRECT: No-op pass-through
@onnx_funcify.register(SpecifyShape)
def onnx_funcify_SpecifyShape(op, node, get_var_name, **kwargs):
    return None

# ‚ùå WRONG: Mixing list and tuple
return ([node1, node2], [initializer])  # Not supported!

# ‚ùå WRONG: Single initializer not in list
return (node, initializer)  # Must be (node, [initializer])
```

---

## Timeline

**Total**: ~30 minutes

1. **Dispatcher extension** (5 min):
   - Modify `basic.py` to handle lists
   - Add documentation to docstring

2. **Shape operations** (10 min):
   - Create `shape.py` dispatch module
   - Implement Shape, Shape_i, SpecifyShape

3. **Tests** (10 min):
   - Create `test_shape.py`
   - Write 5-6 test functions

4. **Verification** (5 min):
   - Run tests
   - Verify no regressions
   - Confirm multi-node pattern works

---

## Next Steps

After Phase 0 completion:

‚úÖ **Ready for Tier 2-3**:
- Dispatcher can handle multi-node operations
- Pattern is documented and tested
- Reference implementation (Shape_i) provides example

üìã **Proceed to**:
- `thoughts/shared/plans/onnx-backend-tier2-3-shape-reductions-tdd.md`
- Implement remaining 30 operations using established patterns

---

## References

### Related Plans:
- **Phase 1-3 infrastructure**: `thoughts/shared/plans/onnx-backend-phase1-3-infrastructure-tdd.md`
- **Tier 2-3 operations**: `thoughts/shared/plans/onnx-backend-tier2-3-shape-reductions-tdd.md`

### Code Locations:
- **Dispatcher**: `pytensor/link/onnx/dispatch/basic.py` (lines 195-205)
- **Shape dispatch**: `pytensor/link/onnx/dispatch/shape.py` (new file)
- **Tests**: `tests/link/onnx/test_shape.py` (new file)

### ONNX Operators:
- **Shape**: https://onnx.ai/onnx/operators/onnx__Shape.html
- **Gather**: https://onnx.ai/onnx/operators/onnx__Gather.html
- **Constant**: https://onnx.ai/onnx/operators/onnx__Constant.html

---

## Post-Implementation Analysis

**Date**: 2025-11-04 21:24:14 CST
**Implementation Period**: 2025-11-04 20:50:20 to 2025-11-04 21:24:14 (~34 minutes)
**Plan Created**: 2025-11-04 21:16:32 CST
**Key Finding**: Implementation was completed BEFORE the plan was created - this is a retrospective documentation plan.

**Relevant Commits**:
- `5999d62` - Add ONNX backend infrastructure and core dispatch system (2025-11-04 20:50:20)
- `ec61d79` - Add ONNX support for shape operations (DimShuffle) (2025-11-04 20:50:42)
- `2cfcaa4` - Implement ONNX dispatcher extension for multi-node operations (Phase 0) (2025-11-04 21:24:14)
- `8e827e9` - Split ONNX Tier 2-3 plan into Phase 0 prerequisite and main implementation (2025-11-04 21:16:32)

### What Worked As Planned

‚úÖ **Dispatcher Extension (Step 0.1)**:
- List return handling implemented exactly as planned in `basic.py:224-230`
- Code matches the plan's proposed implementation verbatim
- Handles `isinstance(result, list)` before tuple check as specified
- Filters None items correctly

‚úÖ **Documentation (Step 0.2)**:
- Return patterns fully documented in `basic.py:140-166`
- All 4 patterns documented with examples
- Notes section matches plan requirements
- Clear examples for each pattern

‚úÖ **Shape Operations (Step 0.3)**:
- Shape, Shape_i, and SpecifyShape all implemented in `shape.py`
- Shape_i demonstrates multi-node pattern with [Constant, Shape, Gather]
- SpecifyShape demonstrates None pattern for pass-through
- Code quality matches plan expectations

‚úÖ **Tests (Step 0.4)**:
- All 5 tests from plan implemented in `test_shape.py`
- Tests cover all patterns: single node, multi-node, None return
- Test structure matches plan exactly
- All tests passing (5/5)

‚úÖ **Success Criteria**:
- All automated checks pass
- No regressions in existing tests
- Dispatcher compiles without errors
- Code is minimal and well-documented

### Divergences from Plan

#### Timeline Anomaly

**Issue**: Plan was created AFTER implementation was complete

- **Planned Timeline**: ~30 minutes
- **Actual Timeline**: ~34 minutes (close match!)
- **Plan Created**: 2025-11-04 21:16:32
- **Implementation Done**: 2025-11-04 21:24:14
- **Why**: This is a retrospective plan documenting what was already implemented. The plan was written based on the successful implementation to guide future Tier 2-3 work.

**Impact**: This is actually a strength - the plan accurately reflects real implementation time and challenges because it was documented immediately after completion.

#### Implementation Details

**Issue**: Additional handler for `type(None)` not in original plan

- **Planned**: Shape, Shape_i, SpecifyShape
- **Actual**: Added `onnx_funcify_None` handler in `shape.py:10-13`
- **Files**: `pytensor/link/onnx/dispatch/shape.py:10-13`
- **Why**: Needed to handle None ops that appear in graph optimizations
- **Commits**: Present in initial implementation (`2cfcaa4`)

**Issue**: DimShuffle implementation included beyond Phase 0 scope

- **Planned**: Phase 0 scope was Shape, Shape_i, SpecifyShape only
- **Actual**: DimShuffle fully implemented with Unsqueeze/Transpose/Squeeze support
- **Files**: `pytensor/link/onnx/dispatch/shape.py:114-200`
- **Commits**: `ec61d79` - Add ONNX support for shape operations (DimShuffle)
- **Why**: Logical grouping - DimShuffle is a core shape operation that belongs with Shape operations
- **Plan Gap**: Should have scoped Phase 0 to "Shape Operations Module" rather than listing specific ops

#### Tests

**Issue**: Test uses Shape_i op directly instead of x.shape[i] syntax

- **Planned**: `y = x.shape[0]` (syntactic sugar)
- **Actual**: `y = Shape_i(0)(x)` (direct op usage)
- **Files**: `tests/link/onnx/test_shape.py:35-36, 55-56, 73-75`
- **Why**: More explicit testing of the operation itself, clearer test intent
- **Impact**: Minor - both approaches test the same functionality

**Issue**: Test names differ slightly from plan

- **Planned**: `test_specify_shape_removed`
- **Actual**: `test_specify_shape_passthrough`
- **Files**: `tests/link/onnx/test_shape.py:90`
- **Why**: "passthrough" more accurately describes the behavior than "removed"
- **Impact**: Positive - better naming

#### Missing Tests

**Issue**: No dedicated test for dispatcher multi-node handling

- **Planned**: `test_onnx_funcify_multi_node_return` and `test_onnx_funcify_list_with_none` in `test_dispatch_basic.py`
- **Actual**: These specific tests not created
- **Why**: Shape_i tests in `test_shape.py` already validate multi-node returns end-to-end
- **Workaround**: `test_shape_i_*` tests verify multi-node pattern works correctly
- **Plan Gap**: Could have been clearer that integration tests would suffice

### Bugs and Fixes Encountered

#### No Significant Bugs

Analysis of git history shows clean implementation with no bug fix commits. The implementation worked correctly on first try, which is unusual and notable.

**Factors Contributing to Success**:
1. Implementation done by same developer who wrote the plan
2. Plan was written immediately after implementation (fresh context)
3. Pattern was well-understood from reviewing existing ONNX backend code
4. Simple, focused scope (just dispatcher extension + 3 operations)

### Success Criteria Analysis

#### Automated Checks (All Passed ‚úÖ)
- [x] Dispatcher code compiles without errors
- [x] All Shape tests pass: `pytest tests/link/onnx/test_shape.py -v` (5/5 passed in 0.30s)
- [x] Shape_i tests pass (multi-node pattern): All 3 Shape_i tests passed
- [x] SpecifyShape test passes (None pattern): `test_specify_shape_passthrough` passed
- [x] All existing Tier 1 tests still pass (no regressions)
- [x] Can import updated dispatcher module

#### Manual Verification (All Satisfied ‚úÖ)
- [x] Code change is minimal (~10 lines to dispatcher, ~112 to shape.py, ~110 test lines)
- [x] Pattern is clear from comments and docstring
- [x] Backward compatible (existing handlers unchanged)
- [x] Shape_i demonstrates multi-node pattern clearly

#### Additional Success Criteria Not in Plan
- [x] DimShuffle operation working (bonus beyond Phase 0 scope)
- [x] `type(None)` handler for graph optimization passes
- [x] Implementation time matched planned timeline (~30 min)

### Lessons Learned

#### For Future Planning

1. **Scope Definition - Be Clear About Boundaries**
   - Plan said "implement one test operation (Shape_i)" but ended up with 4 operations (Shape, Shape_i, SpecifyShape, DimShuffle)
   - Next time: Define scope as "Shape operations module" rather than listing specific ops if flexible scope is intended
   - Or: Be explicit if additional ops are nice-to-have vs out-of-scope

2. **Test Coverage Can Be Implicit**
   - Planned specific dispatcher tests (`test_onnx_funcify_multi_node_return`)
   - Actual: Integration tests (Shape_i) validated the pattern sufficiently
   - Next time: Distinguish between "must-have unit tests" vs "sufficient if covered by integration"

3. **Retrospective Plans Are Valuable**
   - This plan was created after implementation as documentation
   - Benefits: Accurate timeline, real challenges documented, serves as guide for similar work
   - Next time: Consider "implementation log" format for retrospective plans to make the timeline clear

4. **Timeline Estimates Can Be Accurate**
   - Planned: ~30 minutes
   - Actual: ~34 minutes
   - Next time: Breaking down into 5-10 minute chunks is effective for small focused tasks

#### For Test Design

1. **Direct Op Usage vs Syntactic Sugar**
   - Tests used `Shape_i(0)(x)` instead of `x.shape[0]`
   - Benefit: More explicit, easier to understand what's being tested
   - Next time: Document testing philosophy (explicit vs idiomatic) in test design section

2. **Test Naming Matters**
   - Changed "removed" ‚Üí "passthrough" for SpecifyShape test
   - Better names improve code comprehension
   - Next time: Think carefully about verb choice in test names (what behavior, not what implementation)

3. **Integration Tests Can Replace Unit Tests**
   - Shape_i tests validated multi-node pattern without dedicated dispatcher tests
   - Trade-off: Less granular debugging if pattern breaks, but simpler test suite
   - Next time: Document when integration tests are sufficient vs when unit tests are needed

#### For Implementation

1. **Group Related Operations**
   - DimShuffle was added because it naturally belongs with Shape operations
   - Benefit: Cohesive module, easier to find related functionality
   - Next time: Plan at module level rather than operation level when ops are tightly related

2. **Handle Edge Cases Proactively**
   - Added `type(None)` handler for graph optimization passes
   - Discovered during integration, not during unit testing
   - Next time: Research what edge cases might appear (check fgraph optimization passes)

3. **Documentation Patterns Work Well**
   - Four-pattern documentation (single, multiple, tuple, None) is clear
   - Examples in docstring help future implementers
   - Next time: Keep using this pattern for dispatcher extensions

### Recommendations for Next Similar Plan

1. **For Tier 2-3 Implementation**:
   - Use this Phase 0 as a template for planning additional dispatcher features
   - Follow the same pattern: extend dispatcher ‚Üí document ‚Üí implement reference op ‚Üí test
   - Keep scope tight (1-2 hours max) for infrastructure changes

2. **For Dispatcher Extensions**:
   - Always document return patterns in docstring
   - Always provide example operations demonstrating each pattern
   - Always check for edge cases in graph optimization (None ops, identity ops)

3. **For Test Design**:
   - Use direct op instantiation in tests for clarity
   - Name tests by behavior, not implementation
   - Integration tests can validate infrastructure changes when they exercise all code paths

4. **For Retrospective Plans**:
   - Mark clearly that this is documentation of completed work
   - Include actual timeline and compare to what timeline would have been estimated
   - Document surprises and edge cases for future reference

### Patterns Worth Documenting

**Multi-Node Return Pattern**:
```python
# Returning multiple ONNX nodes as a list
return [node1, node2, node3]
```
- Used by: Shape_i (Constant + Shape + Gather)
- Future use: Any operation requiring intermediate computations
- Reference: `pytensor/link/onnx/dispatch/shape.py:98`

**Tuple with Initializers Pattern**:
```python
# Returning node with additional ONNX initializers
return (node, [initializer1, initializer2])
```
- Used by: DimShuffle for axes tensors (ONNX opset 13+)
- Future use: Operations with constant data inputs
- Reference: `pytensor/link/onnx/dispatch/shape.py:158`

**None Return Pattern**:
```python
# Pass-through operation (no ONNX node needed)
return None
```
- Used by: SpecifyShape (optimization hint only)
- Future use: Type annotations, shape assertions, debugging ops
- Reference: `pytensor/link/onnx/dispatch/shape.py:111`

**None Op Handler Pattern**:
```python
@onnx_funcify.register(type(None))
def onnx_funcify_None(op, **kwargs):
    return None
```
- Handles None ops from graph optimizations
- Future use: Always include in new dispatch modules
- Reference: `pytensor/link/onnx/dispatch/shape.py:10-13`

### Open Questions for Future Work

1. **Should dispatcher tests be added anyway?**
   - Current: Integration tests via Shape_i validate the pattern
   - Question: Would dedicated unit tests help when debugging future dispatcher bugs?
   - Recommendation: Add if dispatcher becomes more complex (>3 return patterns)

2. **Should Phase 0 scope have included DimShuffle?**
   - Current: DimShuffle was implemented as part of Phase 0
   - Question: Does this make Phase 0 "too big" or is the module cohesion worth it?
   - Recommendation: Keep cohesive - document as "Shape Operations Module (Phase 0)"

3. **What other None-like ops exist in graph optimizations?**
   - Current: Only handled `type(None)`
   - Question: Are there other pass-through or no-op patterns in PyTensor graphs?
   - Recommendation: Survey graph optimization rewrites for other special cases

4. **How should we handle ONNX opset version differences?**
   - Current: DimShuffle uses opset 13+ pattern (axes as input tensor)
   - Question: Should we support older opsets or always require 13+?
   - Recommendation: Document minimum opset version per operation in docstring

### Key Success Factors

1. ‚úÖ **Small, Focused Scope**: Just dispatcher + 3 core operations
2. ‚úÖ **Clear Success Criteria**: Checklist format made validation easy
3. ‚úÖ **Comprehensive Documentation**: Return patterns documented with examples
4. ‚úÖ **Test Coverage**: All patterns validated through tests
5. ‚úÖ **Clean Implementation**: No bugs, no fixes needed, worked first time

### Comparison: Plan vs Reality

| Aspect | Planned | Actual | Match? |
|--------|---------|--------|--------|
| Timeline | ~30 min | ~34 min | ‚úÖ Very close |
| Dispatcher Extension | List handling | List handling | ‚úÖ Exact |
| Documentation | 4 patterns | 4 patterns | ‚úÖ Complete |
| Operations | Shape, Shape_i, SpecifyShape | +DimShuffle, +None | ‚ö†Ô∏è Scope expansion |
| Tests | 5-6 tests | 5 tests | ‚úÖ Met goal |
| Test Files | test_shape.py, test_dispatch_basic.py | test_shape.py only | ‚ö†Ô∏è Consolidated |
| Bug Fixes | Expected some | Zero bugs | ‚úÖ Clean impl |

---

*This post-implementation analysis documents a retrospective plan created after successful implementation. The analysis helps validate the planning approach and provides insights for future infrastructure work.*
